{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad7d62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f01dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the train datset\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd4b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating dependent and independent features \n",
    "#converting dataframe to numpy array \n",
    "x_train = np.array(train_data.iloc[:,:4])\n",
    "y_train = train_data.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a07c671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting target [0,1] feature values to [-1, 1] values\n",
    "y_train = np.array(y_train.replace(0,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "728c39c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test dataset\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "#test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baddbb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating dependent and independent features \n",
    "#converting dataframe to numpy array \n",
    "x_test = np.array(test_data.iloc[:,:4])\n",
    "y_test = test_data.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e121e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting target [0,1] feature values to [-1, 1] values\n",
    "y_test = np.array(y_test.replace(0,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e954c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, y, gamma):\n",
    "    # Gaussian kernel values is given as : K_rbf(x,y) = exp((-||x-y||^2)/c)\n",
    "    \n",
    "    num = pow(np.linalg.norm(x-y, ord=2),2)\n",
    "    return exp(-num / gamma)\n",
    "\n",
    "class Dual_SVM:\n",
    "    def __init__(self, x, y, C, kernel = \"dot\", gamma=None):\n",
    "        self.w_asterisk = np.ndarray([])\n",
    "        self.b_asterisk = 0.0\n",
    "        self.support = []\n",
    "        \n",
    "                \n",
    "    def func(self, d, gamma, kernel):\n",
    "        #predicting using respective kernel value\n",
    "        if kernel == \"dot\":\n",
    "            return np.sign(np.dot(self.w_asterisk, d) + self.b_asterisk)\n",
    "        \n",
    "        if kernel == \"gaussian\":\n",
    "            return np.sign(gaussian_kernel(self.w_asterisk, d, gamma) + self.b_asterisk)\n",
    "\n",
    "    #predictions for noraml kernel    \n",
    "    def predict_dot(self, x, kernel = \"dot\", gamma = None):\n",
    "        r = [] #list that stores the predicted values of the train dataset\n",
    "        for x_i in x:\n",
    "            r.append(self.func(x_i, gamma, kernel))\n",
    "        return np.array(r) #returning the predictions as an array\n",
    "        \n",
    "    #predictions for gaussian kernel\n",
    "    def predict_gaussian(self, x, kernel = \"gaussian\", gamma = None):\n",
    "        r = [] #list that stores the predicted values of the train dataset\n",
    "        for x_i in x:\n",
    "            r.append(self.func(x_i, gamma, kernel))\n",
    "        return np.array(r) #returning the predictions as an array\n",
    "    \n",
    "    #training the dataset\n",
    "    def train(self, x, y, C, kernel = \"dot\", gamma = None):\n",
    "\n",
    "        #defining the constraints corresponding to the 3 cases\n",
    "        constraints = ({'type': 'ineq',\n",
    "                        'fun': lambda a: a\n",
    "                       },\n",
    "                       {\n",
    "                         'type': 'ineq',\n",
    "                        'fun': lambda a: C - a  \n",
    "                       },\n",
    "                      {\n",
    "                         'type': 'eq',\n",
    "                        'fun': lambda a: np.dot(a, y)  \n",
    "                       })\n",
    "        \n",
    "        temp = len(x) #length of the dataset\n",
    "        res = scipy.optimize.minimize(self.inner_loop, x0=np.zeros(shape=(temp,)), args=(x, y), method='SLSQP', constraints=constraints, tol=0.01)\n",
    "\n",
    "        self.w_asterisk = np.zeros_like(x[0]) #intilizing weight with all zeros\n",
    "        for i in range(len(x)):\n",
    "            self.w_asterisk += res['x'][i]*y[i]*x[i]\n",
    "\n",
    "        self.b_asterisk = 0 #initializing bias with 0\n",
    "        if kernel == \"dot\":\n",
    "            for j in range(len(x)):\n",
    "                self.b_asterisk += y[j] - np.dot(self.w_asterisk, x[j])\n",
    "        \n",
    "        if kernel == \"gaussian\":\n",
    "            for j in range(len(x)):\n",
    "                self.b_asterisk += y[j] - gaussian_kernel(self.w_asterisk, x[j], gamma)\n",
    "        \n",
    "        self.b_asterisk /= len(x)\n",
    "\n",
    "        th = 1e-5 #defining the threshold\n",
    "        for i, a in enumerate(res['x']):\n",
    "            if a > th:\n",
    "                self.support.append(x[i])\n",
    "                \n",
    "    def inner_loop(self, a, x, y, kernel = \"dot\"):\n",
    "        y_res = y * np.ones((len(y), len(y)))\n",
    "        a_res = a * np.ones((len(a), len(a)))\n",
    "\n",
    "        if kernel == \"dot\":\n",
    "            x_values = np.matmul(x, x.T)\n",
    "            \n",
    "        if kernel == \"gaussian\":\n",
    "            temp_val_1 = np.matmul(pow(x, 2), np.ones_like(x.T))\n",
    "            temp_val_2 = np.matmul(np.ones_like(x), pow(x.T, 2))\n",
    "            x_values = temp_val_1 - 2*np.matmul(x,x.T) + temp_val_2 \n",
    "            x_values = np.exp(-( x_values / gamma))\n",
    "\n",
    "        values = (y_res * y_res.T) * (a_res * a_res.T) * x_values\n",
    "        return 0.5 * np.sum(values) - np.sum(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae62341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C =  0.1145475372279496\n",
      "learned weights:  [-0.18009527 -0.2335137   0.05321643 -0.00114814]\n",
      "learned bias:  0.3557453141589707\n",
      "training accuracy:  0.7106773823191733\n",
      "testing accuracy:  0.7034068136272545\n",
      "For C =  0.572737686139748\n",
      "learned weights:  [-0.17873439 -0.23174969  0.05281449 -0.00113921]\n",
      "learned bias:  0.3522513675612511\n",
      "training accuracy:  0.7106773823191733\n",
      "testing accuracy:  0.7034068136272545\n",
      "For C =  0.8018327605956472\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  0.35225132872467174\n",
      "training accuracy:  0.7106773823191733\n",
      "testing accuracy:  0.7034068136272545\n"
     ]
    }
   ],
   "source": [
    "#basic dual SVM implementation for different C values\n",
    "C_vals = [100/873, 500/873, 700/873]\n",
    "\n",
    "for c in C_vals:\n",
    "    d_svm = Dual_SVM(x_train, y_train, c)\n",
    "    print(\"For C = \", c)\n",
    "    d_svm.train(x_train, y_train, c)\n",
    "    print(\"learned weights: \", d_svm.w_asterisk)\n",
    "    print(\"learned bias: \", d_svm.b_asterisk)\n",
    "    print(\"training accuracy: \", np.mean(y_train == d_svm.predict_dot(x_train)))\n",
    "    print(\"testing accuracy: \", np.mean(y_test == d_svm.predict_dot(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea08788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C =  0.1145475372279496\n",
      "For gamma =  0.1\n",
      "learned weights:  [-0.18009527 -0.2335137   0.05321643 -0.00114814]\n",
      "learned bias:  -0.10795290339942785\n",
      "training accuracy:  0.5556831228473019\n",
      "testing accuracy:  0.5571142284569138\n",
      "For C =  0.1145475372279496\n",
      "For gamma =  0.5\n",
      "learned weights:  [-0.18009527 -0.2335137   0.05321643 -0.00114814]\n",
      "learned bias:  -0.11455707008043685\n",
      "training accuracy:  0.574052812858783\n",
      "testing accuracy:  0.5651302605210421\n",
      "For C =  0.1145475372279496\n",
      "For gamma =  1\n",
      "learned weights:  [-0.18009527 -0.2335137   0.05321643 -0.00114814]\n",
      "learned bias:  -0.12320089204165093\n",
      "training accuracy:  0.5855338691159586\n",
      "testing accuracy:  0.5711422845691383\n",
      "For C =  0.1145475372279496\n",
      "For gamma =  5\n",
      "learned weights:  [-0.18009527 -0.2335137   0.05321643 -0.00114814]\n",
      "learned bias:  -0.17158513249695334\n",
      "training accuracy:  0.6417910447761194\n",
      "testing accuracy:  0.6192384769539078\n",
      "For C =  0.1145475372279496\n",
      "For gamma =  100\n",
      "learned weights:  [-0.18009527 -0.2335137   0.05321643 -0.00114814]\n",
      "learned bias:  -0.6890741459977534\n",
      "training accuracy:  0.642939150401837\n",
      "testing accuracy:  0.5751503006012024\n",
      "For C =  0.572737686139748\n",
      "For gamma =  0.1\n",
      "learned weights:  [-0.17873439 -0.23174969  0.05281449 -0.00113921]\n",
      "learned bias:  -0.10795153772174197\n",
      "training accuracy:  0.5556831228473019\n",
      "testing accuracy:  0.5571142284569138\n",
      "For C =  0.572737686139748\n",
      "For gamma =  0.5\n",
      "learned weights:  [-0.17873439 -0.23174969  0.05281449 -0.00113921]\n",
      "learned bias:  -0.11456244993781962\n",
      "training accuracy:  0.574052812858783\n",
      "testing accuracy:  0.5651302605210421\n",
      "For C =  0.572737686139748\n",
      "For gamma =  1\n",
      "learned weights:  [-0.17873439 -0.23174969  0.05281449 -0.00113921]\n",
      "learned bias:  -0.1232071898001219\n",
      "training accuracy:  0.5855338691159586\n",
      "testing accuracy:  0.5711422845691383\n",
      "For C =  0.572737686139748\n",
      "For gamma =  5\n",
      "learned weights:  [-0.17873439 -0.23174969  0.05281449 -0.00113921]\n",
      "learned bias:  -0.17158325313505127\n",
      "training accuracy:  0.6417910447761194\n",
      "testing accuracy:  0.6212424849699398\n",
      "For C =  0.572737686139748\n",
      "For gamma =  100\n",
      "learned weights:  [-0.17873439 -0.23174969  0.05281449 -0.00113921]\n",
      "learned bias:  -0.6891203362483119\n",
      "training accuracy:  0.642939150401837\n",
      "testing accuracy:  0.5751503006012024\n",
      "For C =  0.8018327605956472\n",
      "For gamma =  0.1\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.10795153752347465\n",
      "training accuracy:  0.5556831228473019\n",
      "testing accuracy:  0.5571142284569138\n",
      "For C =  0.8018327605956472\n",
      "For gamma =  0.5\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.11456244986967516\n",
      "training accuracy:  0.574052812858783\n",
      "testing accuracy:  0.5651302605210421\n",
      "For C =  0.8018327605956472\n",
      "For gamma =  1\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.12320718981021746\n",
      "training accuracy:  0.5855338691159586\n",
      "testing accuracy:  0.5711422845691383\n",
      "For C =  0.8018327605956472\n",
      "For gamma =  5\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.17158325290388196\n",
      "training accuracy:  0.6417910447761194\n",
      "testing accuracy:  0.6212424849699398\n",
      "For C =  0.8018327605956472\n",
      "For gamma =  100\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.6891203369321256\n",
      "training accuracy:  0.642939150401837\n",
      "testing accuracy:  0.5751503006012024\n"
     ]
    }
   ],
   "source": [
    "# dual SVM implementation with gaussian kernel for different C and gamma values\n",
    "C_vals = [100/873, 500/873, 700/873]\n",
    "gammas = [0.1, 0.5, 1, 5, 100]\n",
    "for c in C_vals:\n",
    "    for gamma in gammas:\n",
    "        print(\"For C = \", c)\n",
    "        print(\"For gamma = \", gamma)\n",
    "        d_svm.train(x_train, y_train, c, kernel='gaussian', gamma=gamma)\n",
    "        print(\"learned weights: \", d_svm.w_asterisk)\n",
    "        print(\"learned bias: \", d_svm.b_asterisk)\n",
    "        print(\"training accuracy: \", np.mean(y_train == d_svm.predict_gaussian(x_train, kernel='gaussian', gamma=gamma)))\n",
    "        print(\"testing accuracy: \", np.mean(y_test == d_svm.predict_gaussian(x_test, kernel='gaussian', gamma=gamma)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "414b5b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C =  0.8018327605956472\n",
      "For gamma =  0.1\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.10795153752347465\n",
      "number of support vectors:  14807\n",
      "training accuracy:  0.5556831228473019\n",
      "testing accuracy:  0.5571142284569138\n",
      "For C =  0.8018327605956472\n",
      "For gamma =  0.5\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.11456244986967516\n",
      "number of support vectors:  15678\n",
      "training accuracy:  0.574052812858783\n",
      "testing accuracy:  0.5651302605210421\n",
      "For C =  0.8018327605956472\n",
      "For gamma =  1\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.12320718981021746\n",
      "number of support vectors:  16549\n",
      "training accuracy:  0.5855338691159586\n",
      "testing accuracy:  0.5711422845691383\n",
      "For C =  0.8018327605956472\n",
      "For gamma =  5\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.17158325290388196\n",
      "number of support vectors:  17420\n",
      "training accuracy:  0.6417910447761194\n",
      "testing accuracy:  0.6212424849699398\n",
      "For C =  0.8018327605956472\n",
      "For gamma =  100\n",
      "learned weights:  [-0.17873434 -0.23174967  0.05281449 -0.0011392 ]\n",
      "learned bias:  -0.6891203369321256\n",
      "number of support vectors:  18291\n",
      "training accuracy:  0.642939150401837\n",
      "testing accuracy:  0.5751503006012024\n"
     ]
    }
   ],
   "source": [
    "#finding the number of support vectors for different gamma intervals when C = 500/873\n",
    "C_vals = 500/873\n",
    "gammas = [0.1, 0.5, 1, 5, 100]\n",
    "sv = []\n",
    "for gamma in gammas:\n",
    "    print(\"For C = \", c)\n",
    "    print(\"For gamma = \", gamma)\n",
    "    d_svm.train(x_train, y_train, c, kernel='gaussian', gamma=gamma)\n",
    "    print(\"learned weights: \", d_svm.w_asterisk)\n",
    "    print(\"learned bias: \", d_svm.b_asterisk)\n",
    "    print(\"number of support vectors: \", len(d_svm.support))\n",
    "    sv.append(d_svm.support)\n",
    "    print(\"training accuracy: \", np.mean(y_train == d_svm.predict_gaussian(x_train, kernel='gaussian', gamma=gamma)))\n",
    "    print(\"testing accuracy: \", np.mean(y_test == d_svm.predict_gaussian(x_test, kernel='gaussian', gamma=gamma)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdc4df84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap from gamma =  0.1  to  0.5  :  18291\n",
      "overlap from gamma =  0.5  to  1  :  18291\n",
      "overlap from gamma =  1  to  5  :  18291\n",
      "overlap from gamma =  5  to  100  :  18291\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    count = 0\n",
    "    for v in np.array(sv[i]):\n",
    "        if v in np.array(sv[i+1]):\n",
    "            count += 1\n",
    "    print(\"overlap from gamma = \", gammas[i], \" to \", gammas[i+1], \" : \", count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
