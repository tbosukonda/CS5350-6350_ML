{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d45662b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92aac48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3.8384</th>\n",
       "      <th>6.1851</th>\n",
       "      <th>-2.0439</th>\n",
       "      <th>-0.033204</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.85210</td>\n",
       "      <td>9.1710</td>\n",
       "      <td>-3.64610</td>\n",
       "      <td>-1.2047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.24180</td>\n",
       "      <td>10.5388</td>\n",
       "      <td>-4.11740</td>\n",
       "      <td>-4.2797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.26230</td>\n",
       "      <td>12.1177</td>\n",
       "      <td>0.28846</td>\n",
       "      <td>-7.7581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.55298</td>\n",
       "      <td>-3.4619</td>\n",
       "      <td>1.70480</td>\n",
       "      <td>1.1008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15420</td>\n",
       "      <td>7.2756</td>\n",
       "      <td>-2.47660</td>\n",
       "      <td>-1.2099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    3.8384   6.1851  -2.0439  -0.033204  0\n",
       "0  2.85210   9.1710 -3.64610    -1.2047  0\n",
       "1  5.24180  10.5388 -4.11740    -4.2797  0\n",
       "2 -2.26230  12.1177  0.28846    -7.7581  0\n",
       "3  0.55298  -3.4619  1.70480     1.1008  1\n",
       "4  4.15420   7.2756 -2.47660    -1.2099  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\") \n",
    "#train_df.head()\n",
    "test_df = pd.read_csv(\"test.csv\") \n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a943f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = np.array(train_df)\n",
    "test_df = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce238e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "class ANN:\n",
    "    def __init__(self, width, x_train, y_train, question):\n",
    "\n",
    "        self.width = width\n",
    "        self.x = x_train \n",
    "        self.y = y_train \n",
    "        \n",
    "        #defining a list of 1's (bias values) of the length of the train datset\n",
    "        bias = np.transpose(np.array([[1] * x_train.shape[0]])) \n",
    "        #adding the bias term to all the rows in the training data\n",
    "        self.x = np.concatenate((bias, self.x), axis = 1)\n",
    "        #initialising weights randomly\n",
    "        if question == 1:\n",
    "            self.weights = initialize_weights(width, x_train.shape[1]+1)\n",
    "        else:\n",
    "            self.weights = initialize_zero_weights(width, x_train.shape[1]+1)\n",
    "        self.nodes = init_nodes_arr(width, x_train.shape[1]+1)\n",
    "        \n",
    "    def sgd(self, gamma, d, epochs):\n",
    "        \n",
    "        indices = np.arange(0, len(self.x))\n",
    "        \n",
    "        for t in range(epochs):\n",
    "            #shuffling the data\n",
    "            np.random.shuffle(indices)\n",
    "            for i in indices:\n",
    "                x_i = self.x[i]\n",
    "                y_i = self.y[i]\n",
    "                \n",
    "                #calculating the learning rate\n",
    "                temp = (gamma/d)*t\n",
    "                lr = gamma / (1.0 + temp)\n",
    "                \n",
    "                gradient = self.backpropagation(x_i, y_i)\n",
    "                update_weights(self.weights, lr, gradient)\n",
    "                \n",
    "    def backpropagation(self, x_i, y):\n",
    "        cache = [np.zeros(self.width), np.zeros(self.width), np.zeros(1)] #corresponding to the hidden layer 1, hidden layer 2, and output layer\n",
    "        gradient = [np.zeros((self.width, len(x_i))), np.zeros((self.width, self.width)), np.zeros((1, self.width))] #initialize_gradient(self.width, len(x_i))\n",
    "        \n",
    "        #computing cache of output layer\n",
    "        prediction = self.predict(x_i)\n",
    "        cache[2][0] = cross_entropy_deriv(y, (1.0 / (1.0 + np.exp(-prediction))) * deriv_sigmoid_activation_function(prediction))\n",
    "        #computing gradient values\n",
    "        for n in range(self.width):\n",
    "            gradient[2][0][n] = cache[2][0] * self.nodes[2][n]\n",
    "\n",
    "        # back propogate 2nd hidden layer followed by 1st hidden layer to update the cache and gradient values\n",
    "        self.update_layer(cache, gradient, 2, self.width, self.width)\n",
    "        self.update_layer(cache, gradient, 1, len(x_i), self.width)\n",
    "\n",
    "        return gradient\n",
    "    \n",
    "    def update_layer(self, cache, gradient, layer, nodes_prev_layer, nodes_curr_layer):\n",
    "\n",
    "        #Iterating over all nodes except bias\n",
    "        for node in range(1, nodes_prev_layer):\n",
    "            temp = deriv_sigmoid_activation_function(self.nodes[layer][node])\n",
    "            sigmoid_deriv = deriv_sigmoid_activation_function(self.nodes[layer][node])\n",
    "\n",
    "            #outgoing edges from node\n",
    "            edge_out = self.weights[layer][:, node]\n",
    "            deriv = np.dot(cache[layer], edge_out)\n",
    "            cache[layer - 1][node] = deriv * sigmoid_deriv\n",
    "\n",
    "            #incoming edge to node\n",
    "            for edge in range(nodes_prev_layer):\n",
    "                temp = deriv * sigmoid_deriv\n",
    "                gradient[layer - 1][node][edge] = temp * self.nodes[layer - 1][edge]\n",
    "                \n",
    "                \n",
    "    def predict(self, x_i):\n",
    "        self.nodes[0] = x_i\n",
    "        self.predict_layer(1, len(x_i)) #forward propagation for hidden layer 1\n",
    "        self.predict_layer(2, self.width) #forward propagation for hiddem layer 2\n",
    "        \n",
    "        return np.dot(self.weights[2][0], self.nodes[2])\n",
    "\n",
    "    def predict_layer(self, layer_idx, num_nodes):\n",
    "        \n",
    "        for node_idx in range(1, num_nodes):\n",
    "            \n",
    "            #y_j = sum over all nodes of x_i^j-1 * w_i^j-1,j\n",
    "            wt = self.weights[layer_idx - 1][node_idx]\n",
    "            node_val = self.nodes[layer_idx - 1]\n",
    "            total_sum = np.dot(wt, node_val) #wt.dot(node_val)\n",
    "            \n",
    "            #applying activation function over the total sum\n",
    "            self.nodes[layer_idx][node_idx] = (1.0 / (1.0 + np.exp(-total_sum))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c382033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(width, d):\n",
    "    weights = []\n",
    "    weights.append(np.random.rand(width, d)) #layer 1\n",
    "    weights.append(np.random.rand(width, width)) #layer 2\n",
    "    weights.append(np.random.rand(1, width)) #output\n",
    "\n",
    "    return weights\n",
    "\n",
    "def initialize_zero_weights(width, d):\n",
    "    weights = []\n",
    "    weights.append(np.zeros((width, d))) #layer 1\n",
    "    weights.append(np.zeros((width, width))) #layer 2\n",
    "    weights.append(np.zeros((1, width))) #output\n",
    "\n",
    "    return weights\n",
    "\n",
    "def init_nodes_arr(width, d):\n",
    "    nodes = []\n",
    "    nodes.append(np.zeros(d)) # input layer\n",
    "    nodes.append(np.zeros(width)) # hidden layer 1\n",
    "    nodes.append(np.zeros(width)) # hidden layer 2\n",
    "    nodes[1][0] = 1 # hidden layer 2 bias\n",
    "    nodes[2][0] = 1 # hidden layer 2 bias\n",
    "\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def deriv_sigmoid_activation_function(z):\n",
    "    return z * (1.0 - z)\n",
    "\n",
    "\n",
    "def update_weights(weights, lr, gradient):\n",
    "    for layer in range(len(weights)):\n",
    "        weights[layer] = weights[layer] - lr * gradient[layer]\n",
    "\n",
    "def cross_entropy_deriv(y, y_target):\n",
    "    if y==1:\n",
    "        return y_target-1\n",
    "    return y_target\n",
    "\n",
    "def calc_error(NN, test_df):\n",
    "    X = test_df[:, : test_df.shape[1]-1]\n",
    "    y = test_df[:, test_df.shape[1]-1]\n",
    "    size_df = len(test_df)\n",
    "    \n",
    "    #defining a list of 1's (bias values) of the length of the train datset\n",
    "    bias = np.transpose(np.array([[1] * test_df.shape[0]]))\n",
    "    #adding the bias term to all the rows in the training data\n",
    "    X = np.concatenate((bias, X), axis = 1)\n",
    "    \n",
    "    #counter for number of misclassifications\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(size_df):\n",
    "        predict = NN.predict(X[i])\n",
    "        prob = (1.0 / (1.0 + np.exp(-predict)))\n",
    "        \n",
    "        if prob<0.5:\n",
    "            pred = 0\n",
    "        else:\n",
    "            pred = 1\n",
    "            \n",
    "        if y[i] != pred:\n",
    "            cnt += 1\n",
    "\n",
    "    return cnt / size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f590dbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width:  5\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n",
      "Width:  10\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n",
      "Width:  25\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n",
      "Width:  50\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n",
      "Width:  100\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n"
     ]
    }
   ],
   "source": [
    "X = train_df[:, : train_df.shape[1]-1] #independent features of train dataset\n",
    "y = train_df[:, train_df.shape[1]-1]   #dependent features of train dataset\n",
    "widths = [5, 10, 25, 50, 100]\n",
    "for w in widths:\n",
    "    NN = ANN(w, X, y, 1)\n",
    "    NN.sgd(0.1, 0.01, 10) #parameters: gamma, d, epochs\n",
    "    print(\"Width: \", w)\n",
    "    print(\"Training Error: \", calc_error(NN, train_df))\n",
    "    print(\"Test Error: \", calc_error(NN, test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10a47154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width:  5\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n",
      "Width:  10\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n",
      "Width:  25\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n",
      "Width:  50\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n",
      "Width:  100\n",
      "Training Error:  0.5533869115958668\n",
      "Test Error:  0.5571142284569138\n"
     ]
    }
   ],
   "source": [
    "for w in widths:\n",
    "    NN_b = ANN(w, X, y, 2)\n",
    "    NN_b.sgd(0.1, 0.01, 10) #parameters: gamma, d, epochs\n",
    "    print(\"Width: \", w)\n",
    "    print(\"Training Error: \", calc_error(NN_b, train_df))\n",
    "    print(\"Test Error: \", calc_error(NN_b, test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33588e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
